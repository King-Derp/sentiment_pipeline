"""create_raw_events_table_and_drop_raw_submissions

Revision ID: 2dde641de514
Revises: be48d34d59dd
Create Date: 2025-05-26 00:03:14.007518

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '2dde641de514'
down_revision: Union[str, None] = 'be48d34d59dd' # Ensure this points to your PREVIOUS migration
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###

    # 1. Drop the old raw_submissions table if it exists
    op.execute("DROP TABLE IF EXISTS raw_submissions CASCADE")
    # Note: CASCADE is used to also drop dependent objects like indexes or hypertable metadata if any.

    # 2. Create the new raw_events table
    op.create_table('raw_events',
        sa.Column('id', sa.BigInteger(), sa.Identity(start=1, cycle=False), nullable=False, comment='Auto-incrementing primary key'),
        sa.Column('source', sa.Text(), nullable=False, comment="Source system of the event (e.g., 'reddit', 'twitter')"),
        sa.Column('source_id', sa.Text(), nullable=False, comment='Unique identifier of the event within the source system'),
        sa.Column('occurred_at', postgresql.TIMESTAMP(timezone=True), nullable=False, comment='Timestamp when the event originally occurred'),
        sa.Column('payload', postgresql.JSONB(astext_type=sa.Text()), nullable=False, comment='Full event payload as JSON'),
        sa.Column('ingested_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), nullable=False, comment='Timestamp when the event was ingested into the system'),
        sa.Column('processed', sa.Boolean(), server_default=sa.text('false'), nullable=False, comment='Flag indicating if the event has been processed'),
        sa.PrimaryKeyConstraint('id', 'occurred_at', name=op.f('pk_raw_events')),
        sa.UniqueConstraint('source', 'source_id', 'occurred_at', name=op.f('uq_raw_events_source_source_id_occurred_at')),
        comment='Stores raw event data from various sources. Partitioned by occurred_at.'
    )
    op.create_index(op.f('ix_raw_events_occurred_at'), 'raw_events', ['occurred_at'], unique=False)
    op.create_index(op.f('ix_raw_events_source_source_id'), 'raw_events', ['source', 'source_id'], unique=False) # For faster lookups if source is also queried

    # 3. Make raw_events a TimescaleDB hypertable
    op.execute("SELECT create_hypertable('raw_events', 'occurred_at', if_not_exists => TRUE);")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###

    # 1. Drop the raw_events table
    op.execute("DROP TABLE IF EXISTS raw_events CASCADE")

    # 2. Recreate the old raw_submissions table
    op.create_table('raw_submissions',
        sa.Column('id', sa.String(), nullable=False, comment='Reddit base36 ID'),
        sa.Column('created_utc', sa.BigInteger(), nullable=False, comment='Unix epoch timestamp of creation'),
        sa.Column('subreddit', sa.String(), nullable=False, comment='Subreddit name, lowercase'),
        sa.Column('title', sa.Text(), nullable=False, comment='Submission title, UTF-8'),
        sa.Column('selftext', sa.Text(), nullable=True, comment='Submission self-text, may be empty'),
        sa.Column('author', sa.String(), nullable=False, comment="Reddit username of the author, or '[deleted]'"),
        sa.Column('score', sa.Integer(), nullable=False, comment='Submission score (upvotes - downvotes)'),
        sa.Column('upvote_ratio', sa.Float(), nullable=True, comment='Upvote ratio (0.0 to 1.0)'),
        sa.Column('num_comments', sa.Integer(), nullable=False, comment='Number of comments at the time of scrape'),
        sa.Column('url', sa.String(), nullable=False, comment='URL of the submission'),
        sa.Column('flair_text', sa.String(), nullable=True, comment='Flair text, if any'),
        sa.Column('over_18', sa.Boolean(), server_default=sa.text('false'), nullable=False, comment='NSFW (Not Safe For Work) flag'),
        sa.PrimaryKeyConstraint('id', 'created_utc', name='pk_submission_id_created_utc'),
        comment='Stores raw Reddit submission data before processing. Partitioned by created_utc.'
    )
    op.create_index('ix_raw_submissions_subreddit', 'raw_submissions', ['subreddit'], unique=False) # Original index was on (subreddit, created_utc)
    op.create_index('ix_raw_submissions_subreddit_created_utc', 'raw_submissions', ['subreddit', 'created_utc'], unique=False)

    # 3. Make raw_submissions a TimescaleDB hypertable again
    op.execute("SELECT create_hypertable('raw_submissions', 'created_utc', if_not_exists => TRUE);")
    # ### end Alembic commands ###
