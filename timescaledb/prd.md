# PRD: TimescaleDB Integration for Sentiment Pipeline

**Version:** 1.0
**Date:** 2025-05-22
**Author:** Cascade (AI Assistant)

## 1. Introduction & Purpose

This document outlines the Product Requirements for integrating TimescaleDB as the primary data storage solution for the Sentiment Pipeline project. The project involves scraping data from Reddit, performing sentiment analysis, and potentially visualizing this data. 

TimescaleDB, an open-source time-series database built on PostgreSQL, is chosen to handle the large volumes of time-stamped data generated by the Reddit scraper. Its capabilities in efficient time-series data management, automated partitioning (hypertables), and enhanced query performance are crucial for the project's success, especially considering future plans for multiple connected services and growing data volumes.

This PRD will serve as a guide for development, deployment, and ongoing management of the TimescaleDB instance within the project.

## 2. Goals & Success Criteria

### Goals

*   **G1: Reliable Storage:** Establish a robust and persistent storage solution for all raw Reddit submission data collected by the `reddit_scraper` service.
*   **G2: Efficient Time-Series Management:** Leverage TimescaleDB's native time-series capabilities (hypertables, time-based partitioning) to ensure efficient data ingestion and querying.
*   **G3: Scalability:** Design the database setup to handle significant growth in data volume and an increasing number of connected services (e.g., sentiment analysis, visualization tools) without major architectural changes.
*   **G4: Centralized Data Hub:** Position TimescaleDB as the central data repository, accessible by current and future services within the sentiment pipeline ecosystem.
*   **G5: Maintainability:** Ensure the TimescaleDB deployment is manageable, monitorable, and supports standard database administration practices (e.g., backups, security).

### Success Criteria

*   **SC1:** All data scraped by `reddit_scraper` is successfully and consistently stored in TimescaleDB with minimal data loss (<0.01%).
*   **SC2:** Query performance for typical time-bound analyses (e.g., sentiment trends over a specific period) is demonstrably faster compared to a non-time-series optimized PostgreSQL setup, meeting the needs of downstream services (e.g., sentiment service response within X seconds for Y data range).
*   **SC3:** The database can ingest at least [Specify target, e.g., 1 million] new Reddit submissions per day without significant performance degradation.
*   **SC4:** The system remains stable and available (e.g., >99.9% uptime) under normal operational load.
*   **SC5:** Key database metrics (e.g., disk usage, query latency, ingestion rate) are monitorable.
*   **SC6:** The `raw_submissions` table (or equivalent) is successfully converted to and functions as a TimescaleDB hypertable, partitioned by `created_utc`.

## 3. Stakeholders

*   **Development Team (USER & Cascade):** Responsible for implementation, integration, and maintenance.
*   **Future Service Developers:** Will rely on TimescaleDB for data access (e.g., sentiment analysis service, visualization service).
*   **Data Analysts/Users:** Will consume the data and insights derived from it.

## 4. Scope

### In-Scope

*   Deployment of TimescaleDB as a Docker container managed via `docker-compose`.
*   Configuration of the `reddit_scraper` service to write data to TimescaleDB.
*   Creation and management of a hypertable for Reddit submission data, partitioned by the submission creation time (`created_utc`).
*   Basic schema definition for storing Reddit submissions (aligning with `SubmissionORM` from the scraper).
*   Ensuring data persistence through Docker volumes.
*   Basic security configuration (user, password, database access).
*   Providing connectivity for other services within the same Docker network.

### Out-of-Scope (for initial implementation, may be future enhancements)

*   Advanced TimescaleDB features like continuous aggregates, compression policies (unless deemed critical for initial performance/storage targets).
*   Complex multi-node TimescaleDB clustering (initial deployment will be a single node).
*   Automated backup and restore procedures beyond Docker volume persistence (manual procedures or simple scripts might be considered initially).
*   Detailed performance tuning beyond initial hypertable setup.
*   Data migration from other pre-existing storage systems (unless specified as a separate requirement).
*   User interface for database administration (standard PostgreSQL tools like `psql`, DBeaver, pgAdmin will be used).

## 5. Functional Requirements

### FR1: Data Ingestion and Storage

*   **FR1.1 (Data Reception):** The TimescaleDB instance MUST be able to receive structured data (e.g., Reddit submissions) from multiple scraper services via standard PostgreSQL connections.
*   **FR1.2 (Data Persistence):** All ingested data MUST be persistently stored, surviving container restarts and system reboots (achieved via Docker volumes).
*   **FR1.3 (Data Integrity):** The database SHOULD support mechanisms to ensure data integrity, such as primary keys, unique constraints (managed via Alembic), and appropriate data types for submission fields.
*   **FR1.4 (Concurrent Access):** The database MUST support concurrent connections and writes from multiple scraper instances or other services without data corruption.

### FR2: Schema and Hypertable Management (Alembic-Driven)

*   **FR2.1 (Schema Definition and Evolution):**
    *   The database schema (tables, columns, data types, constraints) for data like `raw_submissions` WILL be defined and managed by **Alembic** migration scripts.
    *   SQLAlchemy models within scraper services (e.g., `SubmissionORM`) will reflect this Alembic-managed schema for ORM interaction, but WILL NOT be used to create or alter tables (`metadata.create_all()` should not be used by scrapers for this purpose).
    *   Schema changes and evolutions (e.g., adding new columns) MUST be handled through new Alembic migration scripts.

*   **FR2.2 (TimescaleDB Extension Enablement):**
    *   The `timescaledb` PostgreSQL extension MUST be enabled in the database.
    *   This WILL be handled by an Alembic migration script (e.g., using `op.execute("CREATE EXTENSION IF NOT EXISTS timescaledb CASCADE;")`).

*   **FR2.3 (Hypertable Creation and Configuration):**
    *   Key tables containing time-series data (e.g., `raw_submissions`) MUST be converted into TimescaleDB hypertables.
    *   This conversion (e.g., `SELECT create_hypertable('raw_submissions', 'created_utc', ...)`) WILL be performed by an Alembic migration script following table creation.
    *   The choice of time partitioning column (e.g., `created_utc`) and `chunk_time_interval` will be defined within the Alembic migration.

*   **FR2.4 (Indexing):**
    *   Appropriate indexes MUST be created on hypertables to optimize query performance, particularly on the time partitioning column and any frequently queried columns (e.g., `subreddit`, `id`).
    *   Indexes will be defined and managed via Alembic migrations.

### FR3: Data Access & Querying
*   **FR3.1:** The database must be accessible to other services (e.g., future sentiment analysis service, visualization tools) running within the same Docker network.
*   **FR3.2:** Standard SQL queries, particularly those filtering or aggregating by time ranges, should be supported and perform efficiently.

### FR4: Data Persistence
*   **FR4.1:** Database data must be persisted across container restarts using Docker named volumes.

## 6. Non-Functional Requirements

### NFR1: Performance
*   **NFR1.1:** Ingestion Rate: The system should support an average ingestion rate of [Specify target, e.g., 100 submissions/second] during peak scraping activity.
*   **NFR1.2:** Query Latency: Common analytical queries (e.g., fetching data for a specific subreddit over a 1-week period) should complete within [Specify target, e.g., 5 seconds].

### NFR2: Scalability
*   **NFR2.1:** Data Volume: The system should be designed to store and manage at least [Specify target, e.g., 1TB] of raw submission data or [Specify target, e.g., 500 million] rows efficiently.
*   **NFR2.2:** Connection Handling: The database should support at least [Specify target, e.g., 50] concurrent connections from various services.

### NFR3: Reliability & Availability
*   **NFR3.1:** The database service should restart automatically (`restart: unless-stopped`) if the container or host machine reboots.
*   **NFR3.2:** Data integrity must be maintained; no silent data corruption.

### NFR4: Maintainability
*   **NFR4.1:** The database setup and configuration should be documented (this PRD contributes to this).
*   **NFR4.2:** Standard PostgreSQL tools should be usable for database administration and inspection.

### NFR5: Security
*   **NFR5.1:** Database access must be protected by a username and strong password.
*   **NFR5.2:** Credentials should be managed via environment variables and not hardcoded in configuration files or source code.
*   **NFR5.3:** (Future) Consider separate, less privileged database users for different services based on their access needs.

## 7. Technical Stack & Deployment

*   **TS1: Database Software:** TimescaleDB (latest stable version compatible with PostgreSQL 14 or newer).
*   **TS2: Containerization:** Docker.
*   **TS3: Orchestration:** Docker Compose for local development and multi-container application management.
*   **TS4: Host OS:** Windows (for development environment), Linux (typical for production deployments).
*   **TS5: Client Libraries:** `psycopg2-binary`, `SQLAlchemy` (from the Python services).

## 8. Monitoring & Alerts (Initial Considerations)

*   **M1:** Basic monitoring of container health via `docker ps` and `docker-compose ps`.
*   **M2:** Monitoring of disk space usage for the Docker volume storing TimescaleDB data.
*   **M3:** Observation of query logs and slow queries if performance issues arise.
*   **M4:** (Future) Integration with a dedicated monitoring system (e.g., Prometheus, Grafana) for PostgreSQL/TimescaleDB metrics.

## 9. Risks & Mitigations

*   **R1: Data Volume Exceeds Expectations:**
    *   Mitigation: Regularly monitor disk usage. Implement TimescaleDB compression or adjust `chunk_time_interval` if needed. Plan for storage scaling.
*   **R2: Complex Configuration of TimescaleDB Features:**
    *   Mitigation: Start with basic hypertable setup. Introduce advanced features (compression, continuous aggregates) iteratively as needed, with thorough testing.
*   **R3: Performance Bottlenecks (Ingestion/Query):**
    *   Mitigation: Follow TimescaleDB best practices for schema design. Monitor query performance and optimize critical queries. Ensure proper indexing.
*   **R4: Docker Networking Issues:**
    *   Mitigation: Use custom Docker networks and service names for inter-container communication. Verify network configurations.

## 10. Future Considerations

*   Implementation of TimescaleDB native compression for older data chunks to save storage space.
*   Use of continuous aggregates for pre-calculating common analytical queries.
*   Automated backup and restore strategies.
*   Scaling to a multi-node TimescaleDB cluster if data volume and query load exceed single-node capabilities.
*   More granular security roles for different services accessing the database.

This PRD is a living document and may be updated as the project evolves.
